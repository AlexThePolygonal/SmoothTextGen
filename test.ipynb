{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as ftorch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smoothllm import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_determininsm(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexthepolygonal/.local/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained('roneneldan/TinyStories-33M').to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SmoothModelForCausalLM(\n",
    "    base_model, \n",
    "    embedding_matrix = base_model.get_input_embeddings().weight,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_config = SmoothGenerationConfig()\n",
    "smooth_config.eos_token_id = tokenizer.eos_token_id\n",
    "smooth_config.do_samping = False\n",
    "smooth_config.use_kv_cache = True\n",
    "smooth_config.do_hard_rounding = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_tokens = tokenizer.encode(\"One\", return_tensors=\"pt\").to(device)\n",
    "base_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One day, a little girl named Tim went to the park. He saw a big slide. He wanted to play on it. He ran to the slide and climbed up the steps. He was so happy.\n",
      "\n",
      "But then, he saw a big boy named Sam. Sam was not nice. He wanted to play with Tim. Tim did not want to share. They said, \"No, this is my slide. Go go away!\"\n",
      "\n",
      "Tim was sad. He did not want to fight\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(base_tokens, 100, smooth_config)\n",
    "print(tokenizer.decode(output.toks[0,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import peft\n",
    "\n",
    "config = peft.LoraConfig(\n",
    "    r=8, lora_alpha=16, lora_dropout=0.2, inference_mode=False, task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "finetune_base_model = peft.get_peft_model(base_model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_model = SmoothModelForCausalLM(\n",
    "    finetune_base_model, \n",
    "    base_model.get_input_embeddings().weight,\n",
    ")\n",
    "optimizer = torch.optim.Adam(finetune_model.model.parameters(), 2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1544]]),\n",
       " tensor([[258]]),\n",
       " tensor([[6653]]),\n",
       " tensor([[14363]]),\n",
       " tensor([[26554]]),\n",
       " tensor([[7081]]),\n",
       " tensor([[679]]),\n",
       " tensor([[339]]),\n",
       " tensor([[2399]]),\n",
       " tensor([[465]]),\n",
       " tensor([[6387]]),\n",
       " tensor([[2933]])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_toks = [tokenizer.encode(word, return_tensors=\"pt\").to(device) for word in [\"He\", \"he\", \"His\", \"his\", \"Boy\", \"boy\", \" He\", \" he\", \" His\", \" his\", \" Boy\", \" boy\",\"He \", \"he \", \"His \", \"his \", \"Boy \", \"boy \",]]\n",
    "male_toks = [tok for tok in male_toks if tok.shape[1] == 1]\n",
    "female_toks = [tokenizer.encode(word, return_tensors=\"pt\").to(device) for word in [\"She\", \"she\", \"Her\", \"her\", \"Girl\", \"girl\", \" She\", \" she\", \" Her\", \" her\", \" Girl\", \" girl\",\"She \", \"she \", \"Her \", \"her \", \"Girl \", \"girl \",]]\n",
    "female_toks = [tok for tok in female_toks if tok.shape[1] == 1]\n",
    "\n",
    "\n",
    "\n",
    "def remove_token_loss(toks, tokprobs, list_of_toks = male_toks):\n",
    "  mask = torch.eq(toks, list_of_toks[0])\n",
    "  for tok in list_of_toks:\n",
    "    mask = torch.logical_or(mask, torch.eq(toks, tok))\n",
    "  return ((tokprobs) * mask).sum(dim = -1).sum(dim=-1)\n",
    "\n",
    "def llm_ratio(toks):\n",
    "    llm_rl = ftorch.log_softmax(base_model(toks)[0], dim=-1)[0, torch.arange(toks.shape[1]), toks[0]].sum()  # Log-likelihood of the sequence under finetuned base model\n",
    "    llm_sft = ftorch.log_softmax(finetune_base_model(toks)[0], dim=-1)[0, torch.arange(toks.shape[1]), toks[0]].sum()  # Log-likelihood of the sequence under original base model\n",
    "    return llm_rl - llm_sft\n",
    "\n",
    "def rhlf_loss(toks, tokprobs):\n",
    "   return remove_token_loss(toks, tokprobs, male_toks) - remove_token_loss(toks, tokprobs, female_toks)  - llm_ratio(toks[:, :, 0]) \n",
    "\n",
    "loss = SmoothLoss(rhlf_loss)\n",
    "male_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexthepolygonal/main/prooga/ml/smooth-seq-gen/libv1/gptneo_decompose.py:38: UserWarning: I have absolutely no idea whether it works on other models. Take care\n",
      "  warnings.warn(\"I have absolutely no idea whether it works on other models. Take care\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "143\n",
      "142\n",
      "141\n",
      "140\n",
      "139\n",
      "138\n",
      "137\n",
      "136\n",
      "135\n",
      "134\n",
      "133\n",
      "132\n",
      "131\n",
      "130\n",
      "129\n",
      "128\n",
      "127\n",
      "126\n",
      "125\n",
      "124\n",
      "123\n",
      "122\n",
      "121\n",
      "120\n",
      "119\n",
      "118\n",
      "117\n",
      "116\n",
      "115\n",
      "114\n",
      "113\n",
      "112\n",
      "111\n",
      "110\n",
      "109\n",
      "108\n",
      "107\n",
      "106\n",
      "105\n",
      "104\n",
      "103\n",
      "102\n",
      "101\n",
      "100\n",
      "99\n",
      "98\n",
      "97\n",
      "96\n",
      "95\n",
      "94\n",
      "93\n",
      "92\n",
      "91\n",
      "90\n",
      "89\n",
      "88\n",
      "87\n",
      "86\n",
      "85\n",
      "84\n",
      "83\n",
      "82\n",
      "81\n",
      "80\n",
      "79\n",
      "78\n",
      "77\n",
      "76\n",
      "75\n",
      "74\n",
      "73\n",
      "72\n",
      "71\n",
      "70\n",
      "69\n",
      "68\n",
      "67\n",
      "66\n",
      "65\n",
      "64\n",
      "63\n",
      "62\n",
      "61\n",
      "60\n",
      "59\n",
      "58\n",
      "57\n",
      "56\n",
      "55\n",
      "54\n",
      "53\n",
      "52\n",
      "51\n",
      "50\n",
      "49\n",
      "48\n",
      "47\n",
      "46\n",
      "45\n",
      "44\n",
      "43\n",
      "42\n",
      "41\n",
      "40\n",
      "39\n",
      "38\n",
      "37\n",
      "36\n",
      "35\n",
      "34\n",
      "33\n",
      "32\n",
      "31\n",
      "30\n",
      "29\n",
      "28\n",
      "27\n",
      "26\n",
      "25\n",
      "24\n",
      "23\n",
      "22\n",
      "21\n",
      "20\n",
      "19\n",
      "18\n",
      "17\n",
      "16\n",
      "15\n",
      "14\n",
      "13\n",
      "12\n",
      "11\n",
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "smooth_config.do_sampling = True\n",
    "smooth_config.sampling_temp = 0.5\n",
    "smooth_config.do_hard_rounding = False\n",
    "smooth_config.use_kv_cache = True\n",
    "\n",
    "optimizer = torch.optim.Adam(finetune_model.model.parameters(), 1e-3)\n",
    "\n",
    "grad_test_tokens = tokenizer.encode(\"On this very special day\", return_tensors=\"pt\").to(device)\n",
    "grad_test_output = finetune_model.generate(grad_test_tokens, 170, smooth_config)\n",
    "\n",
    "loss_val = loss(grad_test_output)\n",
    "kv_cache, tokprobs = loss_val.backwards()\n",
    "\n",
    "optimizer.step()\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On|0 this|1 very|2 special|3 day|4,|5 the|6 family|7 wanted|8 to|9 show|10 to|11 the|12 village|13.|14 They|15 were|16 to|17 take|18 the|19 car|20 to|21 the|22 park|23.|24 They|25 were|26 to|27 the|28 park|29.|30\n",
      "|31 saw|32 the|33 swings|34,|35 the|36 slide|37 and|38 the|39 sandbox|40.|41 The|42 little|43 was|44 so|45 happy|46.|47\n",
      "|48\n",
      "|49On|50 their|51 way|52 to|53 the|54 park|55,|56 they|57 saw|58 a|59 big|60 truck|61.|62 It|63 was|64 carrying|65 a|66 lot|67.|68 The|69 driver|70 said|71,|72 \"|73I|74 will|75 take|76 the|77 truck|78.\"|79 |80\n",
      "|81\n",
      "|82The|83 little|84 girl|85 asked|86,|87 \"|88Can|89 I|90 help|91 too|92?\"|93 The|94 driver|95 said|96,|97 \"|98Yes|99,|100 you|101 can|102 help|103.|104 You|105 can|106 drive|107 the|108 truck|109.\"|110\n",
      "|111\n",
      "|112The|113 little|114 girl|115 was|116 so|117 excited|118.|119 She|120 grabbed|121 the|122 truck|123 and|124 started|125 to|126 drive|127.|128 She|129 drove|130 the|131 truck|132 and|133 the|134 car|135.|136 She|137 was|138 so|139 proud|140 to|141 help|142.|143\n",
      "|144<|endoftext|>|145\n"
     ]
    }
   ],
   "source": [
    "# print(tokenizer.decode(grad_test_output.toks[0,:,0]))\n",
    "string = \"\"\n",
    "for i in range(grad_test_output.toks.shape[1]):\n",
    "    string += tokenizer.decode(grad_test_output.toks[0,i,0]) + f\"|{i}\"\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grad_test_tokens = tokenizer.encode(\"On this very special day\", return_tensors=\"pt\").to(device)\n",
    "# grad_test_output = model.generate(grad_test_tokens, 20, smooth_config)\n",
    "\n",
    "# loss_val = loss(grad_test_output)\n",
    "# loss_val.backwards()\n",
    "\n",
    "# optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 On tensor(0.)\n",
      "1  this tensor(0.)\n",
      "2  very tensor(0.)\n",
      "3  special tensor(0.)\n",
      "4  day tensor(-39961.988281)\n",
      "5 , tensor(-123745.484375)\n",
      "6  the tensor(-113648.765625)\n",
      "7  family tensor(58835.558594)\n",
      "8  wanted tensor(-1854.874512)\n",
      "9  to tensor(-3966.811523)\n",
      "10  show tensor(-3858.381836)\n",
      "11  to tensor(1479.171631)\n",
      "12  the tensor(-1823.985962)\n",
      "13  village tensor(1765.571045)\n",
      "14 . tensor(8708.294922)\n",
      "15  They tensor(5229.612305)\n",
      "16  were tensor(11811.407227)\n",
      "17  to tensor(-415.024414)\n",
      "18  take tensor(-6322.558105)\n",
      "19  the tensor(225.293640)\n",
      "20  car tensor(-10.776978)\n",
      "21  to tensor(-348.781128)\n",
      "22  the tensor(2255.238281)\n",
      "23  park tensor(825.040894)\n",
      "24 . tensor(-1238.567993)\n",
      "25  They tensor(559.794250)\n",
      "26  were tensor(-292.560211)\n",
      "27  to tensor(562.008362)\n",
      "28  the tensor(233.114517)\n",
      "29  park tensor(-1016.459229)\n",
      "30 . tensor(318.867706)\n",
      "31 \n",
      " tensor(-22.412958)\n",
      "32  saw tensor(10.452616)\n",
      "33  the tensor(1.275945)\n",
      "34  swings tensor(-16.347237)\n",
      "35 , tensor(-7.878829)\n",
      "36  the tensor(-0.718596)\n",
      "37  slide tensor(-11.743511)\n",
      "38  and tensor(-2.159064)\n",
      "39  the tensor(-2.503654)\n",
      "40  sandbox tensor(-0.362930)\n",
      "41 . tensor(-49.468098)\n",
      "42  The tensor(-65.529221)\n",
      "43  little tensor(-19.491779)\n",
      "44  was tensor(-1.776771)\n",
      "45  so tensor(-2.742556)\n",
      "46  happy tensor(2.903968)\n",
      "47 . tensor(3.163138)\n",
      "48 \n",
      " tensor(4.499805)\n",
      "49 \n",
      " tensor(0.132757)\n",
      "50 On tensor(1.287409)\n",
      "51  their tensor(1.228666)\n",
      "52  way tensor(4.326042)\n",
      "53  to tensor(-2.769740)\n",
      "54  the tensor(-0.748057)\n",
      "55  park tensor(3.829524)\n",
      "56 , tensor(3.354166)\n",
      "57  they tensor(11.881330)\n",
      "58  saw tensor(9.772226)\n",
      "59  a tensor(-10.258364)\n",
      "60  big tensor(-19.813145)\n",
      "61  truck tensor(-1.989425)\n",
      "62 . tensor(-4.148698)\n",
      "63  It tensor(-21.969620)\n",
      "64  was tensor(-35.461918)\n",
      "65  carrying tensor(-41.035446)\n",
      "66  a tensor(8.381620)\n",
      "67  lot tensor(43.042046)\n",
      "68 . tensor(-14.042227)\n",
      "69  The tensor(-23.006289)\n",
      "70  driver tensor(51.589661)\n",
      "71  said tensor(-28.727346)\n",
      "72 , tensor(-6.499719)\n",
      "73  \" tensor(-42.025547)\n",
      "74 I tensor(-57.949287)\n",
      "75  will tensor(7.004543)\n",
      "76  take tensor(-1.792896)\n",
      "77  the tensor(-16.547550)\n",
      "78  truck tensor(-1.650056)\n",
      "79 .\" tensor(0.751952)\n",
      "80   tensor(0.108247)\n",
      "81 \n",
      " tensor(0.084129)\n",
      "82 \n",
      " tensor(0.232270)\n",
      "83 The tensor(-3.887784)\n",
      "84  little tensor(-0.287714)\n",
      "85  girl tensor(-1.312516)\n",
      "86  asked tensor(0.034558)\n",
      "87 , tensor(0.119905)\n",
      "88  \" tensor(0.034813)\n",
      "89 Can tensor(-0.059021)\n",
      "90  I tensor(-0.068803)\n",
      "91  help tensor(-0.073540)\n",
      "92  too tensor(-0.046559)\n",
      "93 ?\" tensor(0.019823)\n",
      "94  The tensor(-0.151161)\n",
      "95  driver tensor(-0.169432)\n",
      "96  said tensor(0.099610)\n",
      "97 , tensor(0.028119)\n",
      "98  \" tensor(-0.034137)\n",
      "99 Yes tensor(0.014002)\n",
      "100 , tensor(-0.135785)\n",
      "101  you tensor(-0.105039)\n",
      "102  can tensor(-0.071710)\n",
      "103  help tensor(-0.262408)\n",
      "104 . tensor(-0.000641)\n",
      "105  You tensor(0.007736)\n",
      "106  can tensor(-0.052239)\n",
      "107  drive tensor(0.108001)\n",
      "108  the tensor(0.018211)\n",
      "109  truck tensor(-0.018677)\n",
      "110 .\" tensor(0.081703)\n",
      "111 \n",
      " tensor(0.071410)\n",
      "112 \n",
      " tensor(0.081262)\n",
      "113 The tensor(-0.015205)\n",
      "114  little tensor(-0.284520)\n",
      "115  girl tensor(-1.173751)\n",
      "116  was tensor(0.062295)\n",
      "117  so tensor(0.012822)\n",
      "118  excited tensor(-0.085452)\n",
      "119 . tensor(0.116764)\n",
      "120  She tensor(-1.051242)\n",
      "121  grabbed tensor(0.019270)\n",
      "122  the tensor(0.072189)\n",
      "123  truck tensor(0.060850)\n",
      "124  and tensor(0.023403)\n",
      "125  started tensor(0.040701)\n",
      "126  to tensor(-0.299691)\n",
      "127  drive tensor(0.028895)\n",
      "128 . tensor(-0.422170)\n",
      "129  She tensor(-1.081673)\n",
      "130  drove tensor(0.728623)\n",
      "131  the tensor(-0.295360)\n",
      "132  truck tensor(-0.005037)\n",
      "133  and tensor(0.046454)\n",
      "134  the tensor(-0.246890)\n",
      "135  car tensor(0.150383)\n",
      "136 . tensor(-0.178661)\n",
      "137  She tensor(-0.334266)\n",
      "138  was tensor(0.749757)\n",
      "139  so tensor(-0.018498)\n",
      "140  proud tensor(-0.380248)\n",
      "141  to tensor(0.015489)\n",
      "142  help tensor(-0.183040)\n",
      "143 . tensor(0.301563)\n",
      "144 \n",
      " tensor(0.)\n",
      "145 <|endoftext|> tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "for i in range(tokprobs.shape[1]):\n",
    "    # print(torch.linalg.vector_norm(kv_cache[0][0][:,:,i,:]))\n",
    "    print(i, tokenizer.decode(grad_test_output.toks[0,i,0]), (tokprobs.grad[0, i, 0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
